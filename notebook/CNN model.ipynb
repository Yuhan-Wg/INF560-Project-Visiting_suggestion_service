{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 367 ms, sys: 103 ms, total: 470 ms\n",
      "Wall time: 438 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../input/data/blocks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2273345, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>latBlock</th>\n",
       "      <th>lngBlock</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>ClientMacAddr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  latBlock  lngBlock  month  day  hour  ClientMacAddr\n",
       "0      0         0        20      4    1    10              1\n",
       "1      0         0        20      4    2    16              1\n",
       "2      0         0        20      4    3    10              1\n",
       "3      0         0        20      4    3    16              1\n",
       "4      0         0        20      4    3    17              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i,r in df[(df.Level==5)&(df.month==4)&(df.day==25)&(df.hour==12)].iterrows():\n",
    "    plt.scatter(r.lngBlock,\n",
    "                r.latBlock,\n",
    "                alpha=r.ClientMacAddr/8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.Level==5)&(df.month==4)&(df.day==25)&(df.hour==12)].ClientMacAddr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latBlock</th>\n",
       "      <th>lngBlock</th>\n",
       "      <th>ClientMacAddr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12.713294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>7.975971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>7.832742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>7.088768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>6.754955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>6.323576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>5.774989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>5.480586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>5.194710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>5.098344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5.015081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4.633858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>4.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>4.474096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>4.027073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>3.914074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>3.830252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>3.729847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>3.707383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>3.703729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>3.673001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>3.489151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>3.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>3.438596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.408060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>3.389856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.270195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3.148965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3.148103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.143976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3.128589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>3.086575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>3.039123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>3.031229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2.981509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.974599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2.973605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2.961083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>2.885086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>2.838428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>2.746781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>2.745626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2.744784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2.730635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>2.728252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>2.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2.674897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>2.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>2.530696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>2.529801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2.505535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.498696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2.434161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>2.399007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>2.394872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>2.376572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.280702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2.215071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>2.208249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2.149842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.026050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>2.025260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.967579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1.961189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1.935678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1.908425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>1.869919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1.811348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.746032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.730640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1.716253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1.707930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1.696746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1.658065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.636667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1.596117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.545050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1.536946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.502890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.479079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.473186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.470320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1.469298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1.445161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1.444175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.442279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1.439834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1.429501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>1.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1.411321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1.410314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1.396923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>1.390476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1.378049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>1.372881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.371324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1.359223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.353591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1.341463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1.340502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1.336471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1.324159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1.318966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.315186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>1.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1.283537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1.282222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.280899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1.265018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1.264331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1.245283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1.227723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1.223810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1.211538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1.209836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1.203509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1.200957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1.199074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1.197183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1.191388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1.185771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1.164384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1.159091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>1.158192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1.153374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1.143541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1.137255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1.135593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1.127072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.101190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1.098214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>1.087248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>1.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>1.074713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1.063291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1.061728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1.049020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1.040816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.029851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     latBlock  lngBlock  ClientMacAddr\n",
       "117         6         9      12.713294\n",
       "140         7        13       7.975971\n",
       "177         9        28       7.832742\n",
       "141         7        14       7.088768\n",
       "157         8        14       6.754955\n",
       "158         8        15       6.323576\n",
       "176         9        27       5.774989\n",
       "164         8        21       5.480586\n",
       "143         7        16       5.194710\n",
       "142         7        15       5.098344\n",
       "139         7        12       5.015081\n",
       "118         6        10       4.633858\n",
       "170         8        27       4.615385\n",
       "159         8        16       4.545455\n",
       "138         7        11       4.474096\n",
       "175         9        26       4.027073\n",
       "153         7        26       3.914074\n",
       "134         6        26       3.830252\n",
       "144         7        17       3.729847\n",
       "152         7        25       3.707383\n",
       "116         6         8       3.703729\n",
       "165         8        22       3.673001\n",
       "166         8        23       3.489151\n",
       "135         6        27       3.444444\n",
       "133         6        25       3.438596\n",
       "35          3         0       3.408060\n",
       "163         8        20       3.389856\n",
       "36          3         1       3.270195\n",
       "91          5         6       3.148965\n",
       "151         7        24       3.148103\n",
       "63          4         3       3.143976\n",
       "160         8        17       3.128589\n",
       "167         8        24       3.086575\n",
       "145         7        18       3.039123\n",
       "174         9        25       3.031229\n",
       "162         8        19       2.981509\n",
       "92          5         7       2.974599\n",
       "137         7        10       2.973605\n",
       "154         7        27       2.961083\n",
       "112         5        27       2.885086\n",
       "129         6        21       2.838428\n",
       "161         8        18       2.746781\n",
       "146         7        19       2.745626\n",
       "121         6        13       2.744784\n",
       "124         6        16       2.730635\n",
       "148         7        21       2.728252\n",
       "127         6        19       2.710526\n",
       "119         6        11       2.674897\n",
       "150         7        23       2.620000\n",
       "128         6        20       2.530696\n",
       "168         8        25       2.529801\n",
       "126         6        18       2.505535\n",
       "64          4         4       2.498696\n",
       "147         7        20       2.434161\n",
       "132         6        24       2.399007\n",
       "149         7        22       2.394872\n",
       "94          5         9       2.376572\n",
       "37          3         2       2.280702\n",
       "120         6        12       2.215071\n",
       "169         8        26       2.208249\n",
       "93          5         8       2.149842\n",
       "66          4         6       2.026050\n",
       "130         6        22       2.025260\n",
       "62          4         2       1.967579\n",
       "123         6        15       1.961189\n",
       "125         6        17       1.935678\n",
       "131         6        23       1.908425\n",
       "156         8        13       1.869919\n",
       "101         5        16       1.811348\n",
       "90          5         5       1.746032\n",
       "69          4         9       1.730640\n",
       "98          5        13       1.716253\n",
       "173         9        24       1.707930\n",
       "106         5        21       1.696746\n",
       "73          4        13       1.658065\n",
       "65          4         5       1.636667\n",
       "75          4        16       1.596117\n",
       "95          5        10       1.545050\n",
       "3           0        18       1.536946\n",
       "100         5        15       1.502890\n",
       "68          4         8       1.479079\n",
       "115         6         7       1.473186\n",
       "38          3         3       1.470320\n",
       "122         6        14       1.469298\n",
       "97          5        12       1.452800\n",
       "96          5        11       1.445161\n",
       "80          4        21       1.444175\n",
       "67          4         7       1.442279\n",
       "111         5        26       1.439834\n",
       "102         5        17       1.429501\n",
       "103         5        18       1.425000\n",
       "105         5        20       1.411321\n",
       "104         5        19       1.410314\n",
       "53          3        19       1.396923\n",
       "86          4        27       1.390476\n",
       "72          4        12       1.378049\n",
       "87          4        28       1.372881\n",
       "26          2        16       1.371324\n",
       "70          4        10       1.359223\n",
       "89          5         4       1.353591\n",
       "110         5        25       1.350000\n",
       "107         5        22       1.341463\n",
       "108         5        23       1.340502\n",
       "74          4        15       1.336471\n",
       "76          4        17       1.324159\n",
       "55          3        21       1.318966\n",
       "41          3         6       1.315186\n",
       "109         5        24       1.285714\n",
       "77          4        18       1.283537\n",
       "71          4        11       1.282222\n",
       "44          3         9       1.280899\n",
       "78          4        19       1.265018\n",
       "50          3        16       1.264331\n",
       "81          4        22       1.245283\n",
       "113         5        28       1.227723\n",
       "83          4        24       1.223810\n",
       "31          2        21       1.211538\n",
       "48          3        13       1.209836\n",
       "79          4        20       1.203509\n",
       "54          3        20       1.200957\n",
       "84          4        25       1.199074\n",
       "51          3        17       1.197183\n",
       "85          4        26       1.191388\n",
       "39          3         4       1.187500\n",
       "82          4        23       1.185771\n",
       "57          3        23       1.164384\n",
       "46          3        11       1.160714\n",
       "2           0        17       1.159091\n",
       "52          3        18       1.158192\n",
       "56          3        22       1.153374\n",
       "47          3        12       1.143541\n",
       "45          3        10       1.140000\n",
       "171         8        28       1.137255\n",
       "49          3        15       1.135593\n",
       "42          3         7       1.127072\n",
       "29          2        19       1.109091\n",
       "43          3         8       1.101190\n",
       "33          2        23       1.100000\n",
       "58          3        24       1.098214\n",
       "1           0        16       1.090909\n",
       "28          2        18       1.087248\n",
       "10          1        17       1.086957\n",
       "136         6        28       1.086957\n",
       "155         7        28       1.083333\n",
       "23          2        12       1.076923\n",
       "172         9        23       1.074713\n",
       "25          2        15       1.066667\n",
       "11          1        18       1.063291\n",
       "30          2        20       1.061728\n",
       "88          4        29       1.058824\n",
       "13          1        20       1.052632\n",
       "27          2        17       1.049020\n",
       "20          2         9       1.048780\n",
       "24          2        13       1.044444\n",
       "9           1        16       1.040816\n",
       "12          1        19       1.029851\n",
       "22          2        11       1.029412\n",
       "59          3        25       1.021277\n",
       "4           0        19       1.000000\n",
       "5           1        11       1.000000\n",
       "7           1        14       1.000000\n",
       "8           1        15       1.000000\n",
       "6           1        13       1.000000\n",
       "99          5        14       1.000000\n",
       "14          1        21       1.000000\n",
       "15          2         3       1.000000\n",
       "16          2         4       1.000000\n",
       "17          2         6       1.000000\n",
       "18          2         7       1.000000\n",
       "19          2         8       1.000000\n",
       "21          2        10       1.000000\n",
       "32          2        22       1.000000\n",
       "34          2        24       1.000000\n",
       "40          3         5       1.000000\n",
       "60          3        26       1.000000\n",
       "61          3        27       1.000000\n",
       "114         5        29       1.000000\n",
       "0           0        15       1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',400)\n",
    "df[df.Level==5].groupby(by=['latBlock','lngBlock']).agg({\"ClientMacAddr\":\"mean\"}).\\\n",
    "reset_index().sort_values(by=\"ClientMacAddr\",ascending=False).head(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3858677, 9)\n",
      "(6187814, 9)\n"
     ]
    }
   ],
   "source": [
    "df_val = df.loc[df.month>=6]\n",
    "df = df.loc[df.month<6]\n",
    "print(df_val.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 50, 50, 7)\n",
      "(4896, 50, 50)\n",
      "Wall time: 21min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# format the input and output\n",
    "def matrixTrans(df, level, between=7):\n",
    "    tf = deepcopy(df.loc[df['Level'] == level])\n",
    "    latMax = tf.latBlock.max()+1\n",
    "    lngMax = tf.lngBlock.max()+1\n",
    "    tf[\"order\"] = tf.month * 10**2+ tf.day\n",
    "    orders = sorted(tf[\"order\"].unique())\n",
    "\n",
    "    def generator():\n",
    "        for hour in tf.hour.unique():\n",
    "            for minute in tf.minute.unique():\n",
    "                yield hour,minute\n",
    "\n",
    "    g = generator()\n",
    "    num = 0\n",
    "    for h,m in g:\n",
    "        num+= len(orders)-between\n",
    "    features = np.zeros((num,lngMax,latMax,between))\n",
    "    labels = np.zeros((num,lngMax,latMax))\n",
    "\n",
    "    g = generator()\n",
    "    index = 0\n",
    "    for hour,minute in g:\n",
    "        temp = tf.loc[(tf.hour==hour)&(tf.minute==minute)]\n",
    "        for i in range(between, len(orders)):\n",
    "            next_ = temp.loc[tf.order==orders[i]]\n",
    "            for _,row in next_.iterrows():\n",
    "                labels[index, row['lngBlock'],row['latBlock']] = row['count']\n",
    "            for b in range(between):\n",
    "                prev = temp.loc[tf.order==orders[i-1-b]]\n",
    "                for _, row in prev.iterrows():\n",
    "                    features[index, row['lngBlock'],row['latBlock'],b] = row['count']\n",
    "            index += 1\n",
    "            if index==num:\n",
    "                return features, labels\n",
    "\n",
    "    del tf\n",
    "    features = features[:index,:,:,:]\n",
    "    labels = labels[:index,:,:]\n",
    "    return features, labels\n",
    "\n",
    "features, labels = matrixTrans(df, 0)\n",
    "features_val, labels_val = matrixTrans(df_val, 0)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    # Input Layer\n",
    "    size = features.shape\n",
    "    kernel_size = [(3,3),(2,2),(2,2),(1,1)]\n",
    "    #pool_size = parameters.get(\"pool_size\", [(2,2),(3,3),(2,2)])\n",
    "    strides = [1,1,1]\n",
    "    filters = [64, 32, 32,1]\n",
    "\n",
    "    input_layer = tf.reshape(features, [-1, size[1], size[2], size[3]])\n",
    "    label_layer = tf.reshape(labels, [-1, size[1]*size[2]])\n",
    "\n",
    "    # We only add conv layers with 'same' padding in our model\n",
    "    # since It's a n*n -> n*n prediction (previous distribution -> future prediction)\n",
    "    # dimensions should be kept same\n",
    "\n",
    "    # Convolutional Layer and Pooling Layer#1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=filters[0],\n",
    "      kernel_size=kernel_size[0],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=conv1,\n",
    "      filters=filters[1],\n",
    "      kernel_size=kernel_size[1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "    \n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=conv2,\n",
    "      filters=filters[2],\n",
    "      kernel_size=kernel_size[2],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "      inputs=conv3,\n",
    "      filters=filters[3],\n",
    "      kernel_size=kernel_size[3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer\n",
    "    conv4_flat = tf.reshape(conv4, [-1, size[1]*size[2]*filters[3]])\n",
    "    #dense = tf.layers.dense(inputs=conv3_flat, units=1024)\n",
    "    #dropout = tf.layers.dropout(inputs=dense, rate=0.8, training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = conv4_flat # tf.layers.dense(inputs=dropout, units= size[1]*size[2], activation=tf.nn.relu)\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.losses.mean_squared_error(labels=label_layer, predictions=logits)\n",
    "    \n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"distribution\": logits\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"mse\": tf.metrics.mean_squared_error(\n",
    "          labels=label_layer, predictions=logits)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\yuhan\\\\AppData\\\\Local\\\\Temp\\\\tmphfq0hzsk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E2368C5240>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build the estimator\n",
    "distribution_estimator = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt.\n",
      "INFO:tensorflow:loss = 28.576378, step = 0\n",
      "INFO:tensorflow:global_step/sec: 3.61906\n",
      "INFO:tensorflow:loss = 407.72498, step = 100 (27.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.58082\n",
      "INFO:tensorflow:loss = 650.3526, step = 200 (27.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.56315\n",
      "INFO:tensorflow:loss = 210.85426, step = 300 (28.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.54967\n",
      "INFO:tensorflow:loss = 560.1207, step = 400 (28.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.55719\n",
      "INFO:tensorflow:loss = 67.3623, step = 500 (28.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.57133\n",
      "INFO:tensorflow:loss = 259.53094, step = 600 (27.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.57336\n",
      "INFO:tensorflow:loss = 1316.235, step = 700 (27.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.59422\n",
      "INFO:tensorflow:loss = 119.727684, step = 800 (27.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.58175\n",
      "INFO:tensorflow:loss = 466.9252, step = 900 (27.920 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 201.6427.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1e2368c53c8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "distribution_estimator.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-11-11:14:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-11-11:14:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 394.2035, mse = 401.83182\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt-1000\n",
      "{'loss': 394.2035, 'mse': 401.83182, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# error on train dataset\n",
    "# print out mse=401, then rmse = 20\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = distribution_estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-11-11:14:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-11-11:14:34\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 250.93202, mse = 253.73146\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmphfq0hzsk\\model.ckpt-1000\n",
      "{'loss': 250.93202, 'mse': 253.73146, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# error on validation dataset\n",
    "# print out mse=253, then rmse = 16\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features_val,\n",
    "    y=labels_val,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = distribution_estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the aim of rmse is 15, for now the rmse from cnn model is 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.220634339470006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((labels_val-np.mean(labels_val))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.23598973610478"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((labels-np.mean(labels))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
