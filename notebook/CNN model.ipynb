{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuhan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../input/blocks.csv\")\n",
    "df[\"minute\"] = df[\"quarter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10046491, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>latBlock</th>\n",
       "      <th>lngBlock</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter</th>\n",
       "      <th>count</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  latBlock  lngBlock  month  day  hour  quarter  count  minute\n",
       "0      0         0        17      4   14    16        0      2       0\n",
       "1      0         0        17      4   21    16        2      1       2\n",
       "2      0         0        17      5   11    11        0      2       0\n",
       "3      0         0        17      5   11    12        0     11       0\n",
       "4      0         0        17      5   11    12        1     11       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3858677, 9)\n",
      "(6187814, 9)\n"
     ]
    }
   ],
   "source": [
    "df_val = df.loc[df.month>=6]\n",
    "df = df.loc[df.month<6]\n",
    "print(df_val.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 50, 50, 7)\n",
      "(4896, 50, 50)\n",
      "Wall time: 21min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# format the input and output\n",
    "def matrixTrans(df, level, between=7):\n",
    "    tf = deepcopy(df.loc[df['Level'] == level])\n",
    "    latMax = tf.latBlock.max()+1\n",
    "    lngMax = tf.lngBlock.max()+1\n",
    "    tf[\"order\"] = tf.month * 10**2+ tf.day\n",
    "    orders = sorted(tf[\"order\"].unique())\n",
    "\n",
    "    def generator():\n",
    "        for hour in tf.hour.unique():\n",
    "            for minute in tf.minute.unique():\n",
    "                yield hour,minute\n",
    "\n",
    "    g = generator()\n",
    "    num = 0\n",
    "    for h,m in g:\n",
    "        num+= len(orders)-between\n",
    "    features = np.zeros((num,lngMax,latMax,between))\n",
    "    labels = np.zeros((num,lngMax,latMax))\n",
    "\n",
    "    g = generator()\n",
    "    index = 0\n",
    "    for hour,minute in g:\n",
    "        temp = tf.loc[(tf.hour==hour)&(tf.minute==minute)]\n",
    "        for i in range(between, len(orders)):\n",
    "            next_ = temp.loc[tf.order==orders[i]]\n",
    "            for _,row in next_.iterrows():\n",
    "                labels[index, row['lngBlock'],row['latBlock']] = row['count']\n",
    "            for b in range(between):\n",
    "                prev = temp.loc[tf.order==orders[i-1-b]]\n",
    "                for _, row in prev.iterrows():\n",
    "                    features[index, row['lngBlock'],row['latBlock'],b] = row['count']\n",
    "            index += 1\n",
    "            if index==num:\n",
    "                return features, labels\n",
    "\n",
    "    del tf\n",
    "    features = features[:index,:,:,:]\n",
    "    labels = labels[:index,:,:]\n",
    "    return features, labels\n",
    "\n",
    "features, labels = matrixTrans(df, 0)\n",
    "features_val, labels_val = matrixTrans(df_val, 0)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    # Input Layer\n",
    "    size = features.shape\n",
    "    kernel_size = [(3,3),(2,2),(2,2),(1,1)]\n",
    "    #pool_size = parameters.get(\"pool_size\", [(2,2),(3,3),(2,2)])\n",
    "    strides = [1,1,1]\n",
    "    filters = [32, 16, 16,1]\n",
    "\n",
    "    input_layer = tf.reshape(features, [-1, size[1], size[2], size[3]])\n",
    "    label_layer = tf.reshape(labels, [-1, size[1]*size[2]])\n",
    "\n",
    "    # We only add conv layers with 'same' padding in our model\n",
    "    # since It's a n*n -> n*n prediction (previous distribution -> future prediction)\n",
    "    # dimensions should be kept same\n",
    "\n",
    "    # Convolutional Layer and Pooling Layer#1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=filters[0],\n",
    "      kernel_size=kernel_size[0],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=conv1,\n",
    "      filters=filters[1],\n",
    "      kernel_size=kernel_size[1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "    \n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=conv2,\n",
    "      filters=filters[2],\n",
    "      kernel_size=kernel_size[2],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.elu)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "      inputs=conv3,\n",
    "      filters=filters[3],\n",
    "      kernel_size=kernel_size[3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer\n",
    "    conv4_flat = tf.reshape(conv4, [-1, size[1]*size[2]*filters[3]])\n",
    "    #dense = tf.layers.dense(inputs=conv3_flat, units=1024)\n",
    "    #dropout = tf.layers.dropout(inputs=dense, rate=0.8, training= mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = conv4_flat # tf.layers.dense(inputs=dropout, units= size[1]*size[2], activation=tf.nn.relu)\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.losses.mean_squared_error(labels=label_layer, predictions=logits)\n",
    "    \n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"distribution\": logits\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"mse\": tf.metrics.mean_squared_error(\n",
    "          labels=label_layer, predictions=logits)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\yuhan\\\\AppData\\\\Local\\\\Temp\\\\tmp9wrleth5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E490C01A20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build the estimator\n",
    "distribution_estimator = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt.\n",
      "INFO:tensorflow:loss = 487.6178, step = 0\n",
      "INFO:tensorflow:global_step/sec: 11.1428\n",
      "INFO:tensorflow:loss = 788.13086, step = 100 (8.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2284\n",
      "INFO:tensorflow:loss = 244.38185, step = 200 (8.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.2298\n",
      "INFO:tensorflow:loss = 665.4614, step = 300 (8.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1675\n",
      "INFO:tensorflow:loss = 162.47899, step = 400 (8.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1343\n",
      "INFO:tensorflow:loss = 289.26343, step = 500 (8.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1075\n",
      "INFO:tensorflow:loss = 669.86676, step = 600 (8.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1068\n",
      "INFO:tensorflow:loss = 457.597, step = 700 (9.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1042\n",
      "INFO:tensorflow:loss = 664.01636, step = 800 (9.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0286\n",
      "INFO:tensorflow:loss = 204.31091, step = 900 (9.067 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 222.16052.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1e490c01908>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "distribution_estimator.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-11-04:42:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-11-04:42:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 402.3088, mse = 410.09708\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt-1000\n",
      "{'loss': 402.3088, 'mse': 410.09708, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# error on train dataset\n",
    "# print out mse=401, then rmse = 20\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = distribution_estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-11-04:42:49\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-11-04:42:51\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 253.90901, mse = 256.74518\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmp9wrleth5\\model.ckpt-1000\n",
      "{'loss': 253.90901, 'mse': 256.74518, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "# error on validation dataset\n",
    "# print out mse=253, then rmse = 16\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features_val,\n",
    "    y=labels_val,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = distribution_estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the aim of rmse is 15, for now the rmse from cnn model is 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.220634339470006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((labels_val-np.mean(labels_val))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.23598973610478"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean((labels-np.mean(labels))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.023269953414626"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256.74518**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
