{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../input/blocks.csv\")\n",
    "df[\"minute\"] = df[\"quarter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10046491, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>latBlock</th>\n",
       "      <th>lngBlock</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter</th>\n",
       "      <th>count</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  latBlock  lngBlock  month  day  hour  quarter  count  minute\n",
       "0      0         0        17      4   14    16        0      2       0\n",
       "1      0         0        17      4   21    16        2      1       2\n",
       "2      0         0        17      5   11    11        0      2       0\n",
       "3      0         0        17      5   11    12        0     11       0\n",
       "4      0         0        17      5   11    12        1     11       1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3858677, 9)\n",
      "(6187814, 9)\n"
     ]
    }
   ],
   "source": [
    "df_val = df.loc[df.month>=6]\n",
    "df = df.loc[df.month<6]\n",
    "print(df_val.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4896, 50, 50, 7)\n",
      "(4896, 50, 50)\n",
      "Wall time: 22min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# format the input and output\n",
    "def matrixTrans(df, level, between=7):\n",
    "    tf = deepcopy(df.loc[df['Level'] == level])\n",
    "    latMax = tf.latBlock.max()+1\n",
    "    lngMax = tf.lngBlock.max()+1\n",
    "    tf[\"order\"] = tf.month * 10**2+ tf.day\n",
    "    orders = sorted(tf[\"order\"].unique())\n",
    "\n",
    "    def generator():\n",
    "        for hour in tf.hour.unique():\n",
    "            for minute in tf.minute.unique():\n",
    "                yield hour,minute\n",
    "\n",
    "    g = generator()\n",
    "    num = 0\n",
    "    for h,m in g:\n",
    "        num+= len(orders)-between\n",
    "    features = np.zeros((num,lngMax,latMax,between))\n",
    "    labels = np.zeros((num,lngMax,latMax))\n",
    "\n",
    "    g = generator()\n",
    "    index = 0\n",
    "    for hour,minute in g:\n",
    "        temp = tf.loc[(tf.hour==hour)&(tf.minute==minute)]\n",
    "        for i in range(between, len(orders)):\n",
    "            next_ = temp.loc[tf.order==orders[i]]\n",
    "            for _,row in next_.iterrows():\n",
    "                labels[index, row['lngBlock'],row['latBlock']] = row['count']\n",
    "            for b in range(between):\n",
    "                prev = temp.loc[tf.order==orders[i-1-b]]\n",
    "                for _, row in prev.iterrows():\n",
    "                    features[index, row['lngBlock'],row['latBlock'],b] = row['count']\n",
    "            index += 1\n",
    "            if index==num:\n",
    "                return features, labels\n",
    "\n",
    "    del tf\n",
    "    features = features[:index,:,:,:]\n",
    "    labels = labels[:index,:,:]\n",
    "    return features, labels\n",
    "\n",
    "features, labels = matrixTrans(df, 0)\n",
    "features_val, labels_val = matrixTrans(df_val, 0)\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(features, labels, mode):\n",
    "    # Input Layer\n",
    "    size = features.shape\n",
    "    kernel_size = [(3,3),(3,3),(3,3)]\n",
    "    #pool_size = parameters.get(\"pool_size\", [(2,2),(3,3),(2,2)])\n",
    "    strides = [2,2,2]\n",
    "    filters = [32, 64, 16]\n",
    "\n",
    "    input_layer = tf.reshape(features, [-1, size[1], size[2], size[3]])\n",
    "    label_layer = tf.reshape(labels, [-1, size[1]*size[2]])\n",
    "\n",
    "    # We only add conv layers with 'same' padding in our model\n",
    "    # since It's a n*n -> n*n prediction (previous distribution -> future prediction)\n",
    "    # dimensions should be kept same\n",
    "\n",
    "    # Convolutional Layer and Pooling Layer#1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=filters[0],\n",
    "      kernel_size=kernel_size[0],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=conv1,\n",
    "      filters=filters[1],\n",
    "      kernel_size=kernel_size[1],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=conv2,\n",
    "      filters=filters[2],\n",
    "      kernel_size=kernel_size[2],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Dense Layer\n",
    "    conv3_flat = tf.reshape(conv3, [-1, size[1]*size[2]*filters[2]])\n",
    "    dense = tf.layers.dense(inputs=conv3_flat, units=1024)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training= True)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units= size[1]*size[2])\n",
    "\n",
    "    # Loss\n",
    "    loss = tf.losses.mean_squared_error(labels=label_layer, predictions=logits)\n",
    "    \n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"distribution\": logits\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    \n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"mse\": tf.metrics.mean_squared_error(\n",
    "          labels=label_layer, predictions=logits)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\yuhan\\\\AppData\\\\Local\\\\Temp\\\\tmpss051w82', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000011D874880B8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    batch_size=512,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1625.4457, step = 0\n",
      "INFO:tensorflow:global_step/sec: 0.560808\n",
      "INFO:tensorflow:loss = 177.97238, step = 100 (178.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.558712\n",
      "INFO:tensorflow:loss = 362.62424, step = 200 (178.983 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 250 into C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 715.8264.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x11e2677be80>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-09-05:31:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-09-05:32:05\n",
      "INFO:tensorflow:Saving dict for global step 250: global_step = 250, loss = 342.47195, mse = 349.07913\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt-250\n",
      "{'loss': 342.47195, 'mse': 349.07913, 'global_step': 250}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features,\n",
    "    y=labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-09-05:32:08\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt-250\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-09-05:32:16\n",
      "INFO:tensorflow:Saving dict for global step 250: global_step = 250, loss = 411.14072, mse = 415.78217\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 250: C:\\Users\\yuhan\\AppData\\Local\\Temp\\tmpss051w82\\model.ckpt-250\n",
      "{'loss': 411.14072, 'mse': 415.78217, 'global_step': 250}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=features_val,\n",
    "    y=labels_val,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the aim of rmse is 15, for now the rmse from cnn model is 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
