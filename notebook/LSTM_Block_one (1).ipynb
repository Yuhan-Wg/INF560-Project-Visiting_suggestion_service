{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "#import  format_output\n",
    "from datetime_extension import timedate_process\n",
    "from produce_rnn_flow import aggregate_time\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level</th>\n",
       "      <th>latBlock</th>\n",
       "      <th>lngBlock</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>h17</th>\n",
       "      <th>h3</th>\n",
       "      <th>h11</th>\n",
       "      <th>h8</th>\n",
       "      <th>h5</th>\n",
       "      <th>...</th>\n",
       "      <th>h15_neighbor2</th>\n",
       "      <th>h16_neighbor2</th>\n",
       "      <th>h17_neighbor2</th>\n",
       "      <th>h18_neighbor2</th>\n",
       "      <th>h19_neighbor2</th>\n",
       "      <th>h20_neighbor2</th>\n",
       "      <th>h21_neighbor2</th>\n",
       "      <th>h22_neighbor2</th>\n",
       "      <th>h23_neighbor2</th>\n",
       "      <th>days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>35.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.5</td>\n",
       "      <td>28.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Level  latBlock  lngBlock  month  day  h17  h3  h11  h8  h5  ...   \\\n",
       "0      0         0        20      4    1    0   0    0   0   0  ...    \n",
       "1      0         0        20      4    2    0   0    0   0   0  ...    \n",
       "2      0         0        20      4    3    1   0    0   0   0  ...    \n",
       "3      0         0        20      4    5    1   0    0   0   0  ...    \n",
       "4      0         0        20      4    6    0   0    0   0   0  ...    \n",
       "\n",
       "   h15_neighbor2  h16_neighbor2  h17_neighbor2  h18_neighbor2  h19_neighbor2  \\\n",
       "0           24.5           80.0           20.0            3.0            1.0   \n",
       "1           16.0           16.5           35.5            2.5            1.5   \n",
       "2           34.0            4.5            7.5            8.5            1.5   \n",
       "3            6.5           30.5           29.5            0.0            4.5   \n",
       "4           16.5           28.5            9.0           12.5            5.5   \n",
       "\n",
       "   h20_neighbor2  h21_neighbor2  h22_neighbor2  h23_neighbor2  days  \n",
       "0            1.0            1.0            1.0            0.0     0  \n",
       "1            1.5            2.0            1.5            0.5     1  \n",
       "2            1.5            1.5            1.5            0.5     2  \n",
       "3           44.5           21.5           14.5           31.5     4  \n",
       "4            9.0            1.5            1.5            0.5     5  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read block data\n",
    "df=pd.read_csv(\"blocks.csv\",header=0)\n",
    "#print(df.shape)\n",
    "df=timedate_process(df)\n",
    "df=aggregate_time(df)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        h17  h3  h11  h8  h5  h14  h4  h6  h18  h12  ...   h15_neighbor2  \\\n",
      "0         0   0    0   0   0    0   0   0    0    0  ...            24.5   \n",
      "1         0   0    0   0   0    0   0   0    0    0  ...            16.0   \n",
      "2         1   0    0   0   0    0   0   0    0    0  ...            34.0   \n",
      "3         1   0    0   0   0    0   0   0    0    1  ...             6.5   \n",
      "4         0   0    0   0   0    0   0   0    0    0  ...            16.5   \n",
      "5         1   0    0   0   0    0   0   0    0    0  ...            10.0   \n",
      "6         0   0    0   0   0    0   0   0    0    0  ...            19.0   \n",
      "7         0   0    0   0   0    0   0   0    0    0  ...            17.0   \n",
      "8         0   0    0   0   0    1   0   0    0    0  ...             4.0   \n",
      "9         0   0    1   0   0    0   0   0    0    0  ...            10.0   \n",
      "10        1   0    0   0   0    0   0   0    1    2  ...             9.5   \n",
      "11        0   0    0   0   0    2   0   0    0    0  ...            17.5   \n",
      "12        0   0    2   0   0    0   0   0    2    0  ...            53.5   \n",
      "13        0   0    0   0   0    0   0   0    0    0  ...            47.5   \n",
      "14        0   0    0   0   0    0   0   0    0    0  ...            17.0   \n",
      "15        0   0    0   0   0    0   0   0    0    0  ...            21.5   \n",
      "16        0   0    0   0   0    0   0   0    0    0  ...             6.5   \n",
      "17        0   0    0   0   0    2   0   0    0    0  ...            45.0   \n",
      "18        1   0    0   0   0    0   0   0    0    0  ...            66.5   \n",
      "19        0   0    0   0   0    0   0   0    0    0  ...            43.5   \n",
      "20        1   0    0   0   0    0   0   0    0    0  ...            14.5   \n",
      "21        0   0    3   0   0    0   0   0    0    0  ...             0.0   \n",
      "22        0   0    0   0   0    1   0   0    0    0  ...            59.0   \n",
      "23        0   0    0   0   0    1   0   0    0    0  ...            20.0   \n",
      "24        0   0    0   0   0    0   0   0    0    0  ...            19.0   \n",
      "25        0   0    0   0   0    0   0   0    0    0  ...            45.0   \n",
      "26        0   0    0   0   0    1   0   0    1    1  ...            48.0   \n",
      "27        0   0    0   0   0    0   0   0    0    0  ...            13.5   \n",
      "28        0   0    0   0   0    0   0   0    0    0  ...            23.0   \n",
      "29        0   0    1   0   0    0   0   0    0    0  ...            25.0   \n",
      "...     ...  ..  ...  ..  ..  ...  ..  ..  ...  ...  ...             ...   \n",
      "164534    8  12    6  10  12   23   9   8    8   23  ...             NaN   \n",
      "164535   27  11   24  12   8   28  11   8   15   26  ...             NaN   \n",
      "164536   25  13   37  14  15   53  12  16   31   71  ...             NaN   \n",
      "164537   17  12   20  17  15   29  12  14   16   27  ...             0.0   \n",
      "164538   27   9   35   8  17   31  10  19   19   30  ...             0.0   \n",
      "164539   32   6   27   7  17   26  14   5   67   39  ...             0.0   \n",
      "164540   20  14   31   7  14   27  16   8   34   35  ...             0.0   \n",
      "164541   22  12   20  15  10   18  14  10   17   21  ...             NaN   \n",
      "164542   20   8   17  12   8   20   9   7   14   19  ...             NaN   \n",
      "164543   17  10   15  10   8   26  11   7   20   25  ...             NaN   \n",
      "164544   21  16   16  15  13   22  14  10   19   16  ...             NaN   \n",
      "164545   19   6   19  15   9   24  12  10   21   29  ...             0.0   \n",
      "164546   17   9   21   6   5   20   5   8   23   26  ...             NaN   \n",
      "164547   25   7   41  10   9   41   6  13   24  106  ...             NaN   \n",
      "164548   15   7   18  12   8   24   7  10   13   22  ...             NaN   \n",
      "164549   19  12   19  17   7   24   8   9   11   35  ...             NaN   \n",
      "164550   19   9   17  14   7   24  11  11   30   23  ...             NaN   \n",
      "164551   20   6   18   8  10   22   9  13   15   18  ...             NaN   \n",
      "164552   18   7   18  14  12   38  11   7   28   19  ...             0.0   \n",
      "164553   33  13   21  19  10   26  15   7   51   29  ...             NaN   \n",
      "164554   24  13   27  12   7   34   7  10   25   40  ...             NaN   \n",
      "164555   22  12   17  12  12   24  11  10   15   18  ...             NaN   \n",
      "164556   22   8   14  11  11   72  13   9   21   25  ...             NaN   \n",
      "164557   17  17   32  15   7   18   9   7   15   29  ...             0.0   \n",
      "164558   35  11   16  14  10   24  15   8   17   19  ...             NaN   \n",
      "164559   18   6   21  11  11   23   6  11   19   24  ...             0.0   \n",
      "164560   27  13   18  11   9   41   9   5   36   30  ...             NaN   \n",
      "164561   20   8   26   8  14   40   9  11   24   45  ...             0.0   \n",
      "164562   17   8   15  14   9   25   9  10   20   17  ...             NaN   \n",
      "164563   20  16   17  16  11   26  12   7   24   44  ...             NaN   \n",
      "\n",
      "        h16_neighbor2  h17_neighbor2  h18_neighbor2  h19_neighbor2  \\\n",
      "0                80.0           20.0            3.0            1.0   \n",
      "1                16.5           35.5            2.5            1.5   \n",
      "2                 4.5            7.5            8.5            1.5   \n",
      "3                30.5           29.5            0.0            4.5   \n",
      "4                28.5            9.0           12.5            5.5   \n",
      "5                 4.5           36.0           38.0            1.5   \n",
      "6                16.0           20.5            7.0            1.5   \n",
      "7                13.0           11.0            5.5            1.5   \n",
      "8                 8.0           26.0            2.0            1.5   \n",
      "9                14.5            7.5            6.5            1.5   \n",
      "10               12.0           28.5            3.0            1.5   \n",
      "11               15.5           21.5            8.0            5.0   \n",
      "12               55.0           50.5           33.0            2.0   \n",
      "13               17.0           30.0            7.0            1.5   \n",
      "14               17.5           13.5            2.5            1.5   \n",
      "15               25.5           26.0            7.0            1.5   \n",
      "16                9.5            6.5            2.5            1.5   \n",
      "17               89.0           50.5           19.5            1.5   \n",
      "18               46.5           28.0           16.5            1.5   \n",
      "19               11.0           15.5            2.0            1.5   \n",
      "20               15.0            9.0            1.5            2.0   \n",
      "21                0.0            0.0            0.0            0.0   \n",
      "22               55.5           18.5            4.0            1.5   \n",
      "23               31.5           14.5            1.5            1.5   \n",
      "24               19.5           21.0           14.5           25.0   \n",
      "25               33.0           15.0            9.5            1.5   \n",
      "26               36.0           14.5           13.5            1.5   \n",
      "27               22.0           14.5            6.5            1.5   \n",
      "28               13.5           15.0            6.0            1.0   \n",
      "29               35.5            6.5            2.0            2.5   \n",
      "...               ...            ...            ...            ...   \n",
      "164534            NaN            NaN            NaN            NaN   \n",
      "164535            NaN            NaN            NaN            NaN   \n",
      "164536            NaN            NaN            NaN            NaN   \n",
      "164537            0.0            0.0            0.0            0.0   \n",
      "164538            0.0            0.0            1.0            0.0   \n",
      "164539            0.0            0.0            0.0            0.0   \n",
      "164540            0.0            0.0            0.0            0.0   \n",
      "164541            NaN            NaN            NaN            NaN   \n",
      "164542            NaN            NaN            NaN            NaN   \n",
      "164543            NaN            NaN            NaN            NaN   \n",
      "164544            NaN            NaN            NaN            NaN   \n",
      "164545            0.0            0.0            0.0            0.0   \n",
      "164546            NaN            NaN            NaN            NaN   \n",
      "164547            NaN            NaN            NaN            NaN   \n",
      "164548            NaN            NaN            NaN            NaN   \n",
      "164549            NaN            NaN            NaN            NaN   \n",
      "164550            NaN            NaN            NaN            NaN   \n",
      "164551            NaN            NaN            NaN            NaN   \n",
      "164552            0.0            0.0            0.0            0.0   \n",
      "164553            NaN            NaN            NaN            NaN   \n",
      "164554            NaN            NaN            NaN            NaN   \n",
      "164555            NaN            NaN            NaN            NaN   \n",
      "164556            NaN            NaN            NaN            NaN   \n",
      "164557            0.0            0.0            1.0            0.0   \n",
      "164558            NaN            NaN            NaN            NaN   \n",
      "164559            0.0            0.0            0.0            0.0   \n",
      "164560            NaN            NaN            NaN            NaN   \n",
      "164561            0.0            2.0            0.0            0.0   \n",
      "164562            NaN            NaN            NaN            NaN   \n",
      "164563            NaN            NaN            NaN            NaN   \n",
      "\n",
      "        h20_neighbor2  h21_neighbor2  h22_neighbor2  h23_neighbor2  days  \n",
      "0                 1.0            1.0            1.0            0.0     0  \n",
      "1                 1.5            2.0            1.5            0.5     1  \n",
      "2                 1.5            1.5            1.5            0.5     2  \n",
      "3                44.5           21.5           14.5           31.5     4  \n",
      "4                 9.0            1.5            1.5            0.5     5  \n",
      "5                 1.5            1.5            1.5            0.5     6  \n",
      "6                 1.5            1.5            1.0            0.0     7  \n",
      "7                 1.5            1.5            1.5            0.5     8  \n",
      "8                 1.5            0.5            1.5            0.0     9  \n",
      "9                 1.5            1.5            1.5            0.0    10  \n",
      "10                0.5            0.5            1.0            0.5    11  \n",
      "11                3.0            2.0            1.5            0.5    12  \n",
      "12                1.5            1.5            1.5            1.0    13  \n",
      "13                1.5            1.5            1.5            1.0    14  \n",
      "14                1.5            1.5            1.5            0.5    16  \n",
      "15                1.5            1.5            1.5            1.0    17  \n",
      "16                1.5            1.5            1.5            0.5    18  \n",
      "17                1.5            1.5            1.5            0.0    20  \n",
      "18                2.0            1.5            1.5            0.5    21  \n",
      "19                1.5            1.5            1.0            0.0    22  \n",
      "20                1.0            1.0            1.0            0.0    25  \n",
      "21                0.0            0.0            0.0            0.0    26  \n",
      "22                0.5            1.0            0.5            0.0    30  \n",
      "23                1.0            1.5            1.0            1.0    32  \n",
      "24                1.5            1.5            1.0            0.0    33  \n",
      "25                1.0            1.0            1.0            0.0    34  \n",
      "26                1.5            0.5            1.0            0.0    35  \n",
      "27                1.0            0.5            0.5            0.5    36  \n",
      "28                1.0            1.0            0.5            0.0    37  \n",
      "29                1.0            1.0            0.5            2.5    38  \n",
      "...               ...            ...            ...            ...   ...  \n",
      "164534            NaN            NaN            NaN            NaN    92  \n",
      "164535            NaN            NaN            NaN            NaN    93  \n",
      "164536            NaN            NaN            NaN            NaN    94  \n",
      "164537            0.0            0.0            0.0            0.0    95  \n",
      "164538            0.0            0.0            0.0            0.0    96  \n",
      "164539            0.0            0.0            0.0            0.0    97  \n",
      "164540            0.0            0.0            0.0            0.0    98  \n",
      "164541            NaN            NaN            NaN            NaN    99  \n",
      "164542            NaN            NaN            NaN            NaN   100  \n",
      "164543            NaN            NaN            NaN            NaN   101  \n",
      "164544            NaN            NaN            NaN            NaN   102  \n",
      "164545            0.0            0.0            0.0            0.0   103  \n",
      "164546            NaN            NaN            NaN            NaN   104  \n",
      "164547            NaN            NaN            NaN            NaN   105  \n",
      "164548            NaN            NaN            NaN            NaN   106  \n",
      "164549            NaN            NaN            NaN            NaN   107  \n",
      "164550            NaN            NaN            NaN            NaN   108  \n",
      "164551            NaN            NaN            NaN            NaN   109  \n",
      "164552            0.0            0.0            0.0            0.0   110  \n",
      "164553            NaN            NaN            NaN            NaN   111  \n",
      "164554            NaN            NaN            NaN            NaN   112  \n",
      "164555            NaN            NaN            NaN            NaN   113  \n",
      "164556            NaN            NaN            NaN            NaN   114  \n",
      "164557            0.0            0.0            0.0            0.0   115  \n",
      "164558            NaN            NaN            NaN            NaN   116  \n",
      "164559            0.0            0.0            0.0            0.0   117  \n",
      "164560            NaN            NaN            NaN            NaN   118  \n",
      "164561            0.0            0.0            0.0            0.0   119  \n",
      "164562            NaN            NaN            NaN            NaN   120  \n",
      "164563            NaN            NaN            NaN            NaN   121  \n",
      "\n",
      "[164564 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(max(df[(level=='0')].latBlock))\n",
    "#df=df[(df.Level==0) & (df.latBlock==0) & (df.lngBlock==20)]\n",
    "df.drop(['Level','latBlock','lngBlock','month','day'], axis=1,inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(0,len(df)):\n",
    "    data.append(df.iloc[i].tolist())\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-1\n",
      "save model： .\\prediction.model-1\n",
      "save model： .\\prediction.model-3\n",
      "save model： .\\prediction.model-5\n",
      "save model： .\\prediction.model-7\n",
      "save model： .\\prediction.model-9\n",
      "save model： .\\prediction.model-11\n",
      "save model： .\\prediction.model-13\n",
      "save model： .\\prediction.model-15\n",
      "save model： .\\prediction.model-17\n",
      "save model： .\\prediction.model-19\n",
      "save model： .\\prediction.model-21\n",
      "save model： .\\prediction.model-23\n",
      "save model： .\\prediction.model-25\n",
      "save model： .\\prediction.model-27\n",
      "save model： .\\prediction.model-29\n",
      "save model： .\\prediction.model-31\n",
      "save model： .\\prediction.model-33\n",
      "save model： .\\prediction.model-35\n",
      "save model： .\\prediction.model-37\n",
      "save model： .\\prediction.model-39\n",
      "save model： .\\prediction.model-41\n",
      "save model： .\\prediction.model-43\n",
      "save model： .\\prediction.model-45\n",
      "save model： .\\prediction.model-47\n",
      "save model： .\\prediction.model-49\n"
     ]
    }
   ],
   "source": [
    "# define parameter\n",
    "rnn_unit = 10  # hidden layer units\n",
    "input_size = 73\n",
    "output_size = 24\n",
    "lr = 0.0006  # learning rate\n",
    "N = 50 #ecope\n",
    "N_model = 2 #each N time save model\n",
    "length = 0\n",
    "# ——————————————————input data——————————————————————\n",
    "length=range(len(data))\n",
    "#print(data)\n",
    "# get train set\n",
    "def get_train_data(batch_size=85, time_step=1, train_begin=0, train_end=length):\n",
    "    batch_index = []\n",
    "    data_train = data[train_begin:train_end]\n",
    "    normalized_train_data = data_train\n",
    "    #print(normalized_train_data)#\n",
    "    train_x, train_y = [], []  # train set\n",
    "    for i in range(len(normalized_train_data) - time_step):\n",
    "        if i % batch_size == 0:\n",
    "            batch_index.append(i)\n",
    "        x = normalized_train_data[i:i + time_step, :73]\n",
    "        y = normalized_train_data[i:i + time_step, 0:24]\n",
    "        train_x.append(x.tolist())\n",
    "        train_y.append(y.tolist())\n",
    "    batch_index.append((len(normalized_train_data) - time_step))\n",
    "    #print(train_y)\n",
    "    return batch_index, train_x, train_y\n",
    "\n",
    "\n",
    "# test set\n",
    "def get_test_data(time_step=1, test_begin=0):\n",
    "    data_test = data[test_begin:]\n",
    "    mean = np.mean(data_test, axis=0)\n",
    "    std = np.std(data_test, axis=0)\n",
    "\n",
    "    normalized_test_data = data_test  # normalized\n",
    "    size = (len(normalized_test_data) + time_step - 1) // time_step  # \n",
    "    test_x, test_y = [], []\n",
    "    for i in range(size - 1):\n",
    "        x = normalized_test_data[i * time_step:(i + 1) * time_step, :73]\n",
    "        y = normalized_test_data[i * time_step:(i + 1) * time_step, 0:24]\n",
    "        test_x.append(x.tolist())\n",
    "        test_y.extend(y)\n",
    "    test_x.append((normalized_test_data[(i + 1) * time_step:, :73]).tolist())\n",
    "    test_y.extend((normalized_test_data[(i + 1) * time_step:, 0:24]).tolist())\n",
    "    return mean, std, test_x, test_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "    #'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "    'out': tf.Variable(tf.random_normal([rnn_unit, output_size]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[rnn_unit, ])),\n",
    "    #'out': tf.Variable(tf.constant(0.1, shape=[1, ]))\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[output_size, ]))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def lstm(X):\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    time_step = tf.shape(X)[1]\n",
    "    w_in = weights['in']\n",
    "    b_in = biases['in']\n",
    "    input = tf.reshape(X, [-1, input_size])  \n",
    "    input_rnn = tf.matmul(input, w_in) + b_in\n",
    "    input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit]) \n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    output_rnn, final_states = tf.nn.dynamic_rnn(cell, input_rnn, initial_state=init_state,\n",
    "                                                 dtype=tf.float32)  \n",
    "    output = tf.reshape(output_rnn, [-1, rnn_unit])  \n",
    "    w_out = weights['out']\n",
    "    b_out = biases['out']\n",
    "    pred = tf.matmul(output, w_out) + b_out\n",
    "    return pred, final_states\n",
    "\n",
    "\n",
    "\n",
    "def train_lstm(batch_size=2, time_step=1, train_begin=0, train_end=10):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "    batch_index, train_x, train_y = get_train_data(batch_size, time_step, train_begin, train_end)\n",
    "    with tf.variable_scope(\"sec_lstm\"):\n",
    "        pred, _ = lstm(X)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.square(tf.reshape(pred, [-1,output_size]) - tf.reshape(Y, [-1,output_size])))\n",
    "    train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "    with tf.Session() as sess:\n",
    "        try:\n",
    "            module_file = tf.train.latest_checkpoint('.')\n",
    "            saver.restore(sess, module_file)\n",
    "        except:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        # 重复训练N次\n",
    "        for i in range(N):\n",
    "            for step in range(len(batch_index) - 1):\n",
    "                _, loss_ = sess.run([train_op, loss], feed_dict={X: train_x[batch_index[step]:batch_index[step + 1]],\n",
    "                                                                 Y: train_y[batch_index[step]:batch_index[step + 1]]})\n",
    "            #print(i, loss_)\n",
    "            if i % N_model:\n",
    "                print(\"save model：\", saver.save(sess, '.\\prediction.model', global_step=i))\n",
    "\n",
    "train_lstm()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n",
      "INFO:tensorflow:Restoring parameters from .\\prediction.model-49\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6f0207485c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[0mrmseBlockRulst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mavg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mRMSE_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "def prediction(time_step=1,time_select=0):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None,time_step,output_size])\n",
    "    mean, std, test_x, test_y = get_test_data(time_step)\n",
    "    with tf.variable_scope(\"sec_lstm\", reuse=True):\n",
    "        pred, _ = lstm(X)\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    with tf.Session() as sess:\n",
    "        module_file = tf.train.latest_checkpoint('.')\n",
    "        saver.restore(sess, module_file)\n",
    "        \n",
    "        \n",
    "        test_predict = []\n",
    "        for step in range(len(test_x) - 1):\n",
    "            prob = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "            predict = prob.reshape((-1,1))\n",
    "            test_predict.extend(predict)\n",
    "        predict_test=[]\n",
    "        for i in range(len(test_predict)):\n",
    "            if i%24==time_select:\n",
    "                predict_test.append(test_predict[i])\n",
    "        #print(predict_test)\n",
    "        y_test=[]\n",
    "        test_y=np.array(test_y).reshape(-1,1)\n",
    "        for i in range(len(test_y)):\n",
    "            if i%24==time_select:\n",
    "                y_test.append(test_y[i])\n",
    "        test_y=np.array(y_test)\n",
    "        test_predict=np.array(predict_test)\n",
    "        test_y=np.nan_to_num(test_y)\n",
    "        test_predict=np.nan_to_num(test_predict)\n",
    "        test_y_result=[]\n",
    "        test_predict_result=[]\n",
    "        for i in test_y:\n",
    "            test_y_result.append(i[0])\n",
    "        for i in test_predict:\n",
    "            test_predict_result.append(i[0])    \n",
    "        test_predict_result=np.array(test_predict_result)\n",
    "        test_y_result=np.array(test_y_result)\n",
    "        result_list=[]\n",
    "        #print(test_predict)\n",
    "        for j in range(0,1936):\n",
    "            target=[]\n",
    "            prediction=[]\n",
    "            target=test_y_result[j*85:(j+1)*85]\n",
    "            prediction=test_predict_result[j*85:(j+1)*85]\n",
    "            error = []\n",
    "            #print(min(len(target),len(prediction)))\n",
    "            for i in range(min(len(target),len(prediction))):\n",
    "                error.append(target[i] - prediction[i])\n",
    "            squaredError = []\n",
    "            absError = []\n",
    "            #print(error)\n",
    "            for val in error:\n",
    "                squaredError.append(val * val)#target-prediction之差平方 \n",
    "                absError.append(abs(val))#误差绝对值\n",
    "            #print(j)\n",
    "            result_list.append(sqrt(sum(squaredError) / len(squaredError)))\n",
    "        return result_list\n",
    "        #print(\"RMSE = \", sqrt(sum(squaredError) / len(squaredError)))#均方根误差RMSE\n",
    "        #plt.figure()\n",
    "        #plt.plot(list(range(len(test_predict))), test_predict, color='b')\n",
    "        #plt.plot(list(range(len(test_y))), test_y,  color='r')\n",
    "        #plt.show()\n",
    "RMSE_result=[]\n",
    "for i in range(0,24):\n",
    "    RMSE_result.append(prediction(1,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5614510611370295, 3.9457362477121483, 18.878151222321453, 25.58673540942206, 2.951961489234882, 0.4766357574587152, 0.863287247044973, 4.02168966635621, 11.921874592652117, 23.06675066026979, 32.51452798039753, 9.56747554287036, 10.378926388773236, 0.6436659013739066, 0.3450382323170576, 0.44071292250684807, 0.6400871234945477, 1.0686649194168123, 4.897650898309291, 11.371406257324608, 22.85023979200875, 30.42253486438499, 15.512145939797165, 21.82828338773885]\n",
      "32.51452798039753\n"
     ]
    }
   ],
   "source": [
    "rmseBlockRulst=[]\n",
    "avg=0\n",
    "for j in range(0,len(RMSE_result)):\n",
    "    avg=0\n",
    "    for i in RMSE_result:\n",
    "        avg=avg+i[j]\n",
    "    rmseBlockRulst.append(avg/24)\n",
    "print(rmseBlockRulst)\n",
    "print(max(rmseBlockRulst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=[4.02168966635621,\n",
    " 4.897650898309291,\n",
    " 9.56747554287036,\n",
    " 10.378926388773236,\n",
    " 11.371406257324608,\n",
    " 11.921874592652117,\n",
    " 15.512145939797165,\n",
    " 18.878151222321453,\n",
    " 21.82828338773885,\n",
    " 22.85023979200875,\n",
    " 23.06675066026979,\n",
    " 25.58673540942206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11685a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAIvCAYAAAAs4hWiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8Zud8P/zPVw7lRyo085DTGFSP2qIjzhpaRdBoqx5p\ni6StlPIr6vf8hB7EsaqoR4PUIY1olbaIaONxKiL1c0iCOLZNGU0iCCEnIZJ8nz/WGnZ39nFm733P\nzHq/X6/7de97Xdda63vfc8/OfHJd61rV3QEAAGB6bjDrAgAAAJgNgRAAAGCiBEIAAICJEggBAAAm\nSiAEAACYKIEQAABgogRCAPZYNfjrqvpGVX1k1vXsCarq8Kq6YIV9j6+qv1nvmgDYcQIhAGuiqrZV\n1VVVdUVVfbmqTq6qm8xpP7mquqqOnLffX4zbjx5f71tVL6qqC8Zjbauqlyxynu2PExYp655J7pfk\nkO4+bO3f9dKq6uiqunas8bKq+kRVPXhO+5bxvZ8+b7+/qarjx58PH/u8fF6fM7d/ZgCwowRCANbS\nQ7r7JknukOSOSZ42r/3fkzxq+4uq2jvJw5P855w+T0uyNclhSfZLcniScxY6z5zHExap51ZJtnX3\nlQs1judfb/9n/Ez2T/LyJG+oqv3n9blLVd19iWNcmeSRVbVlfUoEYKoEQgDWXHd/Ock7MgTDud6W\n5J5VdbPx9QOSnJvky3P63DnJW7r7Sz3Y1t2nrLaGqvrtJK9OcrdxhO6Z26c7VtVTq+rLSf567PuY\nqjqvqi6pqtOq6qA5x+mq+r2q+o+quryqnl1Vt62qD46jfn9fVfuu4DO5Lsnrktw4ye3mNb8gyXOX\n2P2bSU5O8owVvvfjq+ofxpHGy6vqk1X1I1X1tKr6alWdX1W/OKf/QeP7vmT8HB4zp+1G4+juN6rq\nMxn+fDJv3zdV1cVV9YWq+v2V1AjArkEgBGDNVdUhSR6Y5Lx5Td9O8tYkjxhfPyrJ/LD3oSR/MIaw\nn6qq2pEauvs1SR6bcYSuu7eHqVsmuXmG0cNjq+q+Sf40w0jlgUm+mOQN8w53/yQ/m+SuSf53klcm\n+c0khya5fZKjlqunqvZKckyS747nmOvlSX6kqn5hiUM8N8mvVtWPLneu0UMyBNCbJflYhoB+gyQH\nJ3lWkr+a0/cNSS5IclCShyV53vi5JEMIve34uH+SR895TzfIEPI/MR7355M8qaruv8IaAZgxgRCA\ntXRqVV2e5PwkX83CI1qnJHnUOG3y55KcOq/9T5P8WZLfSHJWkgur6tHz+pxaVd+c83hMVu66JM/o\n7u9091XjeU7q7nO6+zsZpqzebd70zBd092Xd/ekkn0ryzu7+fHdfmuTtGabHLuauVfXNDGH4hUl+\ns7u/Oq/PVRkC33MWO8g46npihjC3Eh/o7nd09zVJ/iHJpiTP7+7vZgiAW6pq/6o6NMk9kjy1u7/d\n3R/PMLK6fWrvw5M8t7sv6e7zk7x0zjnunGRTdz+ru6/u7s8neVW+H/gB2MUJhACspYd29/br/n4s\nyQHzO3T3mRnCyR8m+acxlM1tv7a7X9bd98hw3d1zk5xUVT8+7zz7z3m8ahU1Xtzd357z+qDMGbHr\n7iuSfD3DiNd2X5nz81ULvL5JFveh7t4/w0jdaUnutUi/Vye5RVU9ZIlj/VmS+1fVzyzRZ7v5NX6t\nu6+d8zoZ6j4oySXdffmc/l/M99//QRkC/ty27W6V5KC54TzJ05PcYgX1AbALEAgBWHPd/f4M17y9\ncJEuf5PkKbn+dNH5x7mqu1+W5BtJfmKtypv3+ksZgk2SpKpunOSHkly4RucbTjoEzcdlWBzmeiOK\n3X11kmcmeXaSBafJdvfXk7xk7LNWvpTk5lW135xtm/P9939Rhqmxc9u2Oz/JF+aF8/26+4g1rA+A\ndSQQArBeXpLkfouMZr00w+0gzpjfUFVPGhd/uVFV7T1OF90vw3Vw6+HvkhxTVXeoqh9I8rwkH+7u\nbWt9ou6+JMNI4J8s0uV1SW6YYbGdxbw4yd2T/PgSfVZT0/lJPpjkT6vqhlX100l+O0NoT5K/T/K0\nqrrZeG3o/5yz+0eSXD4u0nOjqtqrqm5fVf9t4RkAdl0CIQDrorsvzjACeL3wM16P9p7unj9alyTf\nSvKiDCuPfi3J45P86nh92nZvm3cfwrfsRJ3vTvLHSd6UYTTstlnfa+BekuSIMXjNr+XaDJ/XzRfb\nubsvy7Aq6aJ9dsBRSbZkGC18S4ZrLN89tj0zwzTRLyR5Z4bQOrfeB2dYTfYLGf68Xp3kpmtYGwDr\nqBb+bzEAAAB7OiOEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABO196wLWA8HHHBAb9myZdZl\nAAAAzMTZZ5/9te7etFy/PTIQbtmyJWedddasywAAAJiJqvriSvqZMgoAADBRAiEAAMBECYQAAAAT\nJRACAABMlEAIAAAwUQIhAADARAmEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABMlEAIAAEyU\nQAgAADBRAiEAAMBECYQAAAATJRACAABMlEAIAAAwUTMNhFV1w6r6SFV9oqo+XVXPXKBPVdVLq+q8\nqjq3qu40i1oBAAD2NHvP+PzfSXLf7r6iqvZJcmZVvb27PzSnzwOT3G583CXJK8ZnAAAAdsJMRwh7\ncMX4cp/x0fO6HZnklLHvh5LsX1UHbmSdAAAAe6KZX0NYVXtV1ceTfDXJu7r7w/O6HJzk/DmvLxi3\nAQAAsBNmPWU03X1tkjtU1f5J3lJVt+/uT632OFV1bJJjk2Tz5s1rXCUAALurLcf986xL2K1se/6D\nZl0CG2jmI4Tbdfc3k7w3yQPmNV2Y5NA5rw8Zt83f/5XdvbW7t27atGn9CgUAANhDzHqV0U3jyGCq\n6kZJ7pfkc/O6nZbkUeNqo3dNcml3X7TBpQIAAOxxZj1l9MAkr62qvTKE07/v7n+qqscmSXefmOT0\nJEckOS/Jt5IcM6tiAQAA9iQzDYTdfW6SOy6w/cQ5P3eSx29kXQAAAFOwy1xDCAAAwMYSCAEAACZK\nIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiB\nEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRC\nAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggB\nAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQA\nAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAA\nYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACA\niRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAm\nSiAEAACYKIEQAABgogRCAACAiZppIKyqQ6vqvVX1mar6dFU9cYE+h1fVpVX18fHxJ7OoFQAAYE+z\n94zPf02Sp3T3OVW1X5Kzq+pd3f2Zef0+0N0PnkF9AAAAe6yZjhB290Xdfc748+VJPpvk4FnWBAAA\nMBW7zDWEVbUlyR2TfHiB5rtX1blV9faq+skNLQwAAGAPNespo0mSqrpJkjcleVJ3Xzav+Zwkm7v7\niqo6IsmpSW63wDGOTXJskmzevHmdKwYAANj9zXyEsKr2yRAG/7a73zy/vbsv6+4rxp9PT7JPVR2w\nQL9XdvfW7t66adOmda8bAABgdzfrVUYryWuSfLa7X7xIn1uO/VJVh2Wo+esbVyUAAMCeadZTRu+R\n5JFJPllVHx+3PT3J5iTp7hOTPCzJ46rqmiRXJXlEd/csigUAANiTzDQQdveZSWqZPickOWFjKgIA\nAJiOmV9DCAAAwGwIhAAAABMlEAIAAEyUQAgAADBRAiEAAMBECYQAAAATJRACAABMlEAIAAAwUQIh\nAADARAmEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABMlEAIAAEyUQAgAADBRAiEAAMBECYQA\nAAATJRACAABMlEAIAAAwUQIhAADARAmEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABMlEAIA\nAEyUQAgAADBRAiEAAMBECYQAAAATJRACAABMlEAIAAAwUQIhAADARAmEAAAAEyUQAgAATJRACAAA\nMFECIQAAwEQJhAAAABMlEAIAAEyUQAgAADBRAiEAAMBECYQAAAATJRACAABMlEAIAAAwUQIhAADA\nRAmEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABMlEAIAAEyUQAgAADBRAiEAAMBECYQAAAAT\nJRACAABMlEAIAAAwUQIhAADARAmEAAAAEyUQAgAATJRACAAAMFECIQAAwEQJhAAAABMlEAIAAEyU\nQAgAADBRAiEAAMBECYQAAAATJRACAABMlEAIAAAwUQIhAADARM00EFbVoVX13qr6TFV9uqqeuECf\nqqqXVtV5VXVuVd1pFrUCAADsafae8fmvSfKU7j6nqvZLcnZVvau7PzOnzwOT3G583CXJK8ZnAAAA\ndsJMRwi7+6LuPmf8+fIkn01y8LxuRyY5pQcfSrJ/VR24waUCAADscWY9Qvg9VbUlyR2TfHhe08FJ\nzp/z+oJx20Xz9j82ybFJsnnz5vUqc6dsOe6fZ13CbmXb8x806xJ2K75frDd/JwFgz7NLLCpTVTdJ\n8qYkT+ruy3bkGN39yu7e2t1bN23atLYFAgAA7IFmHgirap8MYfBvu/vNC3S5MMmhc14fMm4DAABg\nJ8x6ldFK8pokn+3uFy/S7bQkjxpXG71rkku7+6JF+gIAALBCs76G8B5JHpnkk1X18XHb05NsTpLu\nPjHJ6UmOSHJekm8lOWYGdQIAAOxxZhoIu/vMJLVMn07y+I2pCAAAYDpmfg0hAAAAsyEQAgAATNSK\nA2FVnVRVv7RMnwdX1Uk7XxYAAADrbTUjhEcnucMyfX4myaN3uBoAAAA2zFpPGf2BJNeu8TEBAABY\nB6sNhL1YQ1X9QJJ7J/nyTlUEAADAhljythNV9fl5m55cVQvdB3CvJJsyjBCeuEa1AQAAsI6Wuw/h\nDfL9UcHOcM/Ahe4b+N0kn0zyniTPWbPqAAAAWDdLBsLu3rL956q6LslfdPez1rsoAAAA1t9yI4Rz\n3SfJtnWqAwAAgA224kDY3e9fz0IAAADYWKsZIUySVNXWJIcluVmGxWTm6+5+9s4WBgAAwPpacSCs\nqh9M8uYMU0cXWlhmu04iEAIAAOziVjNC+OdJ7pvkA0n+Osn5Sa5Zj6IAAABYf6sJhEcmOSfJfbr7\nunWqBwAAgA1yg1X0vWmS9wqDAAAAe4bVBML/SHKL9SoEAACAjbWaQPiyJA+pqoPXqxgAAAA2zmqu\nIXx7hkVl/rWqnpnk7CTfXKhjd//XGtQGAADAOlpNINyW4ZYSleTVS/TrVR4XAACAGVhNcDslQ9gD\nAABgD7DiQNjdR69jHQAAAGyw1SwqAwAAwB5EIAQAAJioFU8ZraqTVti1u/u3d7AeAAAANshqFpU5\nepn27SuQdhKBEAAAYBe3mkB460W275/kzkn+OMkHkxy3s0UBAACw/lazyugXF2n6YpJPVNU7kpyb\n5N1JXrMGtQEAALCO1mxRme4+P8nbkjxxrY4JAADA+lnrVUa/kuR2a3xMAAAA1sGaBcKq2ivJfZNc\nulbHBAAAYP2s5rYT917iGIcmOSbJHZK8eg3qAgAAYJ2tZpXR92W4pcRiKskZSf6fnSkIAACAjbGa\nQPisLBwIr0vyjSQf6e6PrElVAAAArLvV3Hbi+HWsAwAAgA221quMAgAAsJtYzZTRJElV/Y8kv5Lk\njkn2z7Cq6DlJ3tLdV65teQAAAKyXVQXCqjoiyWuT3DzDIjLbdZK/qKpjuvuf1rA+AAAA1slqbjtx\npyRvTrJXkr9N8i9JLkpyYIb7Dx6V5B+r6h7dffY61AoAAMAaWs0I4R9mGAm8V3d/aF7byVX1sgy3\npnh6kl9dm/IAAABYL6tZVOZeSf5hgTCYJOnuDyf5x7EfAAAAu7jVBMKbJjl/mT7/leQHd7wcAAAA\nNspqAuGXkhy2TJ+tGa4rBAAAYBe3mkB4epL7VtVxVbXX3IaqukFVPSXJL4z9AAAA2MWtZlGZZyd5\naJLnJvndqvpAhtHAWya5Z5ItSb6c5DlrXCMAAADrYMWBsLu/XFX3SPJXSe6X5FbzurwryWO725RR\nAACA3cCqbkzf3duS3L+qDk5yxwwLzVya5GPdfeHalwcAAMB6WVUg3G4MfwIgAADAbmzZRWWq6sFV\n9ciq2meJPvuOfR60tuUBAACwXpYMhFX1U0lOTbK1u7+7WL/uvjrDLSlOraqfXNsSAQAAWA/LjRD+\nVpJvJ3nmCo71rCRXJ/mdnS0KAACA9bdcIDw8yfu7+5LlDtTdFyd5X5L77nxZAAAArLflAuFtk3x2\nFcf7bIb7EQIAALCLWy4Q7pthGuhKXZ3kB3a8HAAAADbKcoHwkiSbV3G8zUm+vuPlAAAAsFGWC4Tn\nJLlfVS076ldVN0xyvyQfW4vCAAAAWF/LBcK3JNmU5LkrONazkhyQ5E07WxQAAADrb7lAeEqSzyV5\nclW9rqpuN79DVf1wVZ2S5CkZFpV53dqXCQAAwFrbe6nG7v5uVT00yXuS/EaSX6+qC5NcMHY5OMkh\nSWrc9tDuvmYd6wUAAGCNLDdCmO7+9yQ/m+Q1GVYRPSTJXcfHoeO2VyfZ2t3nrV+pAAAArKUlRwi3\n6+6vJnlMVf3PJFuTHDg2XZTkrO7+9jrVBwAAwDpZUSDcbgx+Z65TLQAAAGygZaeMAgAAsGcSCAEA\nACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmasWBsKp+foX9nrmKY55UVV+tqk8t0n54VV1aVR8f\nH3+y0mMDAACwtNWMEL6pqn5qqQ5V9fQkf7SKY56c5AHL9PlAd99hfDxrFccGAABgCasJhFcmOb2q\nDlmosaqenOQ5ST640gN29xlJLllFDQAAAKyR1QTCI5Lsl+TtVXXTuQ1V9bgkL0ry0SQPXLvykiR3\nr6pzq+rtVfWTa3xsAACAyVpxIOzuTyT51SQ/kuStVbVvklTV7yQ5Icknkty/u69Yw/rOSbK5u386\nyV8mOXWxjlV1bFWdVVVnXXzxxWtYAgAAwJ5pVauMdvd7kvx2knsleV1VPSrJiUk+l+QXuvuba1lc\nd1+2PWB29+lJ9qmqAxbp+8ru3trdWzdt2rSWZQAAAOyR9l7tDt39N+N1hM9L8rAk/5nk57v762td\nXFXdMslXurur6rAMAXbNzwMAADBFiwbCqtq8xH6vT3JYhpHCY5LsO7d/d//XSk5eVX+X5PAkB1TV\nBUmekWSf8RgnZgicj6uqa5JcleQR3d0rOTYAAABLW2qEcFuS5cJXJTlj3rZe5rjf79h91DLtJ2S4\nPhEAAIA1tlRwOyXLB0IAAAB2U4sGwu4+egPrAAAAYIOtapVRAAAA9hwrDoRVtamq7l1V+y3S/oNj\n+4K3hQAAAGDXspoRwj9K8rYk1y7Sfu3Y/rSdLQoAAID1t5pAeL8k7+ruby3U2N1XJnlnkvuvRWEA\nAACsr9UEwkMz3IR+KZ8f+wEAALCLW00g7CT7LtNn3yR77Xg5AAAAbJTVBMJ/yxLTQauqxvbzdrYo\nAAAA1t9qAuE/Jvmxqjqhqm40t2F8fUKSH03yxjWsDwAAgHWy6I3pF/DSJEcleVySh1bVGUkuTHJw\nknsnOSjJJ5K8ZK2LBAAAYO2tOBB291VVdXiSlyd5eJJHzGm+Lsnrkzyhu69a0woBAABYF6sZIUx3\nfzPJr1fVE5PcOcn+Sb6Z5CPd/bV1qA8AAIB1sqpAuF13X5zk9DWuBQAAgA20Q4Gwqg5JcscMI4SX\nJjmnuy9Yy8IAAABYX6sKhFV1qyR/leR+C7S9K8lju3vb2pQGAADAelpxIKyqWyY5M8OqotuSnJHk\noiQHJrlXkl9McmZVbe3uL699qQAAAKyl1YwQ/nGGMPjUJC/u7mu3N1TVXkmenOQFSf4oyRPWskgA\nAADW3mpuTP+gJO/s7j+fGwaTpLuv7e4XJnlnkgevZYEAAACsj9UEwlsmOXuZPmeP/QAAANjFrSYQ\nXprkVsv02Tz2AwAAYBe3mkB4ZpKHVdXdF2qsqrsk+bWxHwAAALu41Swq89wM1xG+v6rekOS9GVYZ\nvWWSw5McleS6JM9b4xoBAABYBysOhN19TlU9LMlrk/xGkl+f01xJLknyW9293HWGAAAA7AJWdWP6\n7v6nqtqc5Mgkd0py0wzXDH4syandfeXalwgAAMB6WFUgTJIx9L1+fAAAALCbWs2iMgAAAOxBFh0h\nrKpH7ehBu/uUHd0XAACAjbHUlNGTk/Qqj1fjPgIhAADALm6pQHjMhlUBAADAhls0EHb3azeyEAAA\nADaWRWUAAAAmatW3nZirqg7OcD/CGyT5YHdfvCZVAQAAsO6WHSGsqp+uqpOq6m1V9SdVdeNx+7OT\nfD7JqUnenOT8qnry+pYLAADAWllyhLCqfizJmUlunGEF0SOS3Kmq3pDkD5NcmeSTSW6W5NZJXlhV\nn+juf1nXqgEAANhpy40QHpfkJkleluSXkpyQ5CEZwuB7kxzS3Vu7+7ZJfmXc5wnrVCsAAABraLlr\nCH8uyb929++Pr/+pqu6U5O5JjunuS7d37O5Tq+rtSe6yPqUCAACwlpYbITwwyUfmbdv++tML9P9M\nkk07WxQAAADrb7lAuG+SS+dtuyxJuvuqBfpfmWSvNagLAACAdeY+hAAAABO1kkDY614FAAAAG24l\nN6Y/vqqOn7+xqq5d+3IAAADYKCsJhLXKYxpRBAAA2A0sGQi72zWGAAAAeyiBDwAAYKIEQgAAgIkS\nCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkog\nBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQ\nAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKJmGgir6qSq+mpVfWqR9qqql1bVeVV1blXdaaNr\nBAAA2FPNeoTw5CQPWKL9gUluNz6OTfKKDagJAABgEmYaCLv7jCSXLNHlyCSn9OBDSfavqgM3pjoA\nAIA9296zLmAZByc5f87rC8ZtF83vWFXHZhhFzObNmzekOABYzJbj/nnWJbAH2/b8B826BPZgfn+t\nzu7+93HWU0bXTHe/sru3dvfWTZs2zbocAACAXd6uHggvTHLonNeHjNsAAADYSbt6IDwtyaPG1Ubv\nmuTS7r7edFEAAABWb6bXEFbV3yU5PMkBVXVBkmck2SdJuvvEJKcnOSLJeUm+leSY2VQKAACw55lp\nIOzuo5Zp7ySP36ByAAAAJmVXnzIKAADAOhEIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZK\nIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiB\nEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRC\nAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggB\nAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQA\nAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAA\nYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACA\niRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJmnkgrKoH\nVNW/VdV5VXXcAu2HV9WlVfXx8fEns6gTAABgT7P3LE9eVXsleVmS+yW5IMlHq+q07v7MvK4f6O4H\nb3iBAAAAe7BZjxAeluS87v58d1+d5A1JjpxxTQAAAJMw60B4cJLz57y+YNw2392r6tyqentV/eRC\nB6qqY6vqrKo66+KLL16PWgEAAPYosw6EK3FOks3d/dNJ/jLJqQt16u5XdvfW7t66adOmDS0QAABg\ndzTrQHhhkkPnvD5k3PY93X1Zd18x/nx6kn2q6oCNKxEAAGDPNOtA+NEkt6uqW1fVvkkekeS0uR2q\n6pZVVePPh2Wo+esbXikAAMAeZqarjHb3NVX1hCTvSLJXkpO6+9NV9dix/cQkD0vyuKq6JslVSR7R\n3T2zogEAAPYQMw2EyfemgZ4+b9uJc34+IckJG10XAADAnm7WU0YBAACYEYEQAABgogRCAACAiRII\nAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAE\nAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAA\nAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAA\ngIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAA\nJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACY\nKIEQAAAF8/vKAAAOrUlEQVRgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZK\nIAQAAJgogRAAAGCiBEIAAICJEggBAAAmSiAEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiB\nEAAAYKIEQgAAgIkSCAEAACZq5oGwqh5QVf9WVedV1XELtFdVvXRsP7eq7jSLOgEAAPY0Mw2EVbVX\nkpcleWCSn0hyVFX9xLxuD0xyu/FxbJJXbGiRAAAAe6hZjxAeluS87v58d1+d5A1JjpzX58gkp/Tg\nQ0n2r6oDN7pQAACAPc2sA+HBSc6f8/qCcdtq+wAAALBKe8+6gLVSVcdmmFKaJFdU1b/Nsp7dwAFJ\nvjbrIpZSfzbrCtiF7fLf3z2Rv5NryneYnTLjv4++v+zO1vz7uwv/9/FWK+k060B4YZJD57w+ZNy2\n2j7p7lcmeeVaF7inqqqzunvrrOuAHeH7y+7Od5jdme8vuzPf3+ub9ZTRjya5XVXduqr2TfKIJKfN\n63NakkeNq43eNcml3X3RRhcKAACwp5npCGF3X1NVT0jyjiR7JTmpuz9dVY8d209McnqSI5Kcl+Rb\nSY6ZVb0AAAB7kllPGU13n54h9M3dduKcnzvJ4ze6rgkwvZbdme8vuzvfYXZnvr/sznx/56khbwEA\nADA1s76GEAAAgBkRCCemqrZV1Ser6uNVddas64HlVNVJVfXVqvrUnG03r6p3VdV/jM83m2WNsJhF\nvr/HV9WF4+/hj1fVEbOsERZTVYdW1Xur6jNV9emqeuK43e9gdgtLfIf9Hp7DlNGJqaptSbZ2t/sH\nsVuoqnsnuSLJKd19+3HbC5Jc0t3Pr6rjktysu586yzphIYt8f49PckV3v3CWtcFyqurAJAd29zlV\ntV+Ss5M8NMnR8TuY3cAS3+GHx+/h7zFCCOzSuvuMJJfM23xkkteOP782wy932OUs8v2F3UJ3X9Td\n54w/X57ks0kOjt/B7CaW+A4zh0A4PZ3k3VV1dlUdO+tiYAfdYs79SL+c5BazLAZ2wP+sqnPHKaWm\n27HLq6otSe6Y5MPxO5jd0LzvcOL38PcIhNNzz+6+Q5IHJnn8OJ0JdlvjrWnMfWd38ookt0lyhyQX\nJXnRbMuBpVXVTZK8KcmTuvuyuW1+B7M7WOA77PfwHALhxHT3hePzV5O8Jclhs60IdshXxusCtl8f\n8NUZ1wMr1t1f6e5ru/u6JK+K38Pswqpqnwz/kP7b7n7zuNnvYHYbC32H/R7+7wTCCamqG48X1Kaq\nbpzkF5N8aum9YJd0WpJHjz8/OslbZ1gLrMr2f0iPfjl+D7OLqqpK8pokn+3uF89p8juY3cJi32G/\nh/87q4xOSFXdJsOoYJLsneT13f3cGZYEy6qqv0tyeJIDknwlyTOSnJrk75NsTvLFJA/vbgt3sMtZ\n5Pt7eIZpSp1kW5LfnXM9FuwyquqeST6Q5JNJrhs3Pz3DNVh+B7PLW+I7fFT8Hv4egRAAAGCiTBkF\nAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEABYlao6uaq6qrbMuhYAdo5ACDAh4z/i5z6u\nrapLqup9VXX0eBPf+ftsmdP/iqrab5FjV1X955y+hy/Q535V9Zaq+lJVXV1V36iqf6+qf6iq359/\n/gXqXehxvfPsasbPd8Pv8zTnz+7kjT73SszqcwHg+/aedQEAzMQzx+d9kvxwkl9O8nNJtiZ5wiL7\nXJPkxhlu6PvKBdp/Psltxn7X++9LVT09yXPH9v8vyb8luTbJbcdzPyzJy8f2xepdyLYl2gCAJQiE\nABPU3cfPfV1V90hyRpLfq6oXdfcXFtjt7CS3SvKYLBwIH5PkO0n+JckD5x3/VkmeleSyJPfs7k/O\na79BkvtlCIjL1gsArA1TRgFId/9rks8lqSQ/u0i3a5L8dZKtVfUzcxuq6oAkD03ypiSXLLDvXZLs\nleS988PgeP7ruvsd3b2u0wer6uFVdUZVXVpVV1XVJ6vqaVX1Awv03TY+blxVf15V/1VV36mq86rq\nqQtNr13gGFvGKZE/N76eO9X1ffP6HlJVJ1TV58fzfL2qTquqOy9w3P2q6o+r6lNVdVlVXT5O131j\nVf3s2Of4JNuD/aPnnfvoFX5ev1BVH6iqK8epxadW1Y8t0f/oqnrT+B6uGmv716r6zR35XKrqPlX1\nyqr6zHisq8b3/IyquuFK3gMASzNCCMB8312i7dVJjsswGjh3aumjk+yb5FVJfmeB/b4+Pt+mqvbq\n7gVHAtdTVT0vydOSfC3J65NckWEk83lJ7l9Vv9jdV8/bbZ8k70hyUJK3ZwjFD03y/CQ3zNJTWZPk\nm2OfozOMrs7tv21ObXdK8s4kNx/P9+Yk20P2mVX1y919+ti3Mky5vXuS/5Phz+SaJIckuU+SD2QY\nzX1fkv2TPDHJJ5KcOufcH1+m7lTVw5K8McnV4/NFSe45nvPcRXZ7RZJPZxhtvijJDyU5IsnrqupH\nu/uPV/O5JHlqkh9L8sEk/5zhM79HkuOTHF5VvzCL7xLAnqTW+X/GArAL2b6AR3fPX7zl3knemyFY\nbOnui+a0bckw0vSv3X3Pqnp3hlHEg7r7qrHPZ5Ps1d0/UlV/k+Q3ktynu983tt84Q1C4VYbAcnKS\nDyf53FL/oJ+z4Mhiwevb3f38Fbzvu2UIFecnOay7vzxu3zvJW5I8OMkfdvfz5uyzbaz37Ul+dc57\n/b+S/PvYbVN3LxWgtx/rfUl+bv7nPqeGz2UIdPfv7vfPaTsoyUczzOjZ0t3fqaqfyhDITu3uX553\nrBskuWl3f2N8vSXDn91ru/vo5eqcc5ybJPlikh9McrfuPmtO218kedL48tbdvW1O2227+z/nHWvf\nDJ/hvcf3cOFKPpex/TZJvjB/5Liqnp3kj5I8orvfuNL3BcD1mTIKMEFVdfz4eG5VvTHJuzNMF/1f\nc8PgIl6VYeTp18Zj3SvDKM6rF9uhu69M8ksZRqbuleQ1ST6V5PKqen9V/d5C0zbneMYij+OWfbOD\n3xqfn7M9DI51XZPkKUmuy8Ijm0ny+9vD4LjPV5O8NclNk/zoCs+/lAdlWFjnL+eGwfFcX0rygiS3\nzLBoz1xXzXu9fertN9agpiMzjFa+fm4YHB2f5NKFdpofBsdtVyd5WYZZSfPfw5K6+/OLTCP+i/H5\n/qs5HgDXZ8oowDQ9Y97rTvLb3f3XK9j3LRmmXT4mySlJjs0wzfTkpXbq7nOT3LGqtmaY2ninJHfL\nMHJ07yTHVtV9Fgo0i40grcKdxud/WeDY/15VFyS5dVXdtLvnhp1Lu/u8BY53/vh8s52sKxk+gyS5\n1Xjd33y3G59/PMnpST6TIVgfNS7W89YkZyY5a4Eprztq++f1/vkN3X1pVX084/V/c1XV5gzTPH8+\nyeYkN5rX5eDVFDGOLD8xwyq4P5Jkvwz/42KHjgfA9QmEABO0PWCN/+C+W4YRuxOr6ovdfb3QNG/f\nq6vqlCR/ME7FfFiS08aRs5Wc+6wkc6cgHpbktUl+JkNQfdIiu+6Mm47Pi41+XpQhwOyf/z769c1F\n+m+/NcZeO19afmh8/rVl+t0kSbr72qq6b5I/yfDZ/9nYfnlVvTbJ07r7ip2safvn9ZVF2r88f8M4\nvfMjGULyBzJcE3lphpVjt2S4znSpUeD5x9snQ4A/LMNo8huTXJzvX+P6jNUcD4CFCYQAEzZO5Xx3\nVT0kyTlJXjsu/vGtZXZ9VZI/SPL3GRb6WOg2FCut4SNV9YQM01bvu6PHWcb2kHfLJNeb1pjkwHn9\nNtL2cx7Z3aetZIdxFPXJSZ5cVT+cYbTudzMs9LN/kkeuUU23WKT9lgts+4MM4faY7j55bkNVHZUh\nEK7GkRnC4Mndfcy84x2Y649yA7ADXEMIwPbpnK/KsLDJk1fQ/3MZRoEOybAq5Lt2soTLx+ednRq6\nmI+Nz4fPbxgD1SEZFi9ZbERwZ107nmuhEcUPjc/32pEDd/d53f2aDKHwigxB6r+dN6sfyTxnfF5o\nWuhNk9xhgX1+eHx+0wJt1zvOaKnPZfvx3ryK4wGwSgIhANs9J8ON5f9XVa3k2rhjM1zb9SvL3T+w\nqg4b71E3/5qy7VMDnzq+PGOVNa/USePzH1XVpjnn3ivJCzP89/A163Tu5Pu33di8QNtbM4xaPr6q\njlho56q6W1X9j/HnW4/TM+e7WYYplHMXm/lGhutDFzrvUt467vvr4zWfcx2f708pnWvb+Hz4vNrv\nn8UX7Fnqc1nseLfJ96fJArCTTBkFIEnS3RdW1YkZFvH43xnu2bdU/89luF3CShyU4ab2J1TVmRkW\nRvl2hqmaD8gwBfG8JM9aaOdFFlvZ7tTuXvK+et39wap6QYb39amq+sckV2a4D+HtMyzK8ucrfC87\n4j0ZrhF8c1WdniG0fbG7X9fd362qX8lw/8F/rqoPZlg05ltJDk1y5yS3yfBZfSvDtZZvrqqPJvls\nki8l2ZRhZHCfzAlL3X1FVX04yb2q6m8z3C7j2gzXfC52L8Ht+x2b4bq9D4wr0W6/D+HtMwT3e8/b\n7eVJjknyD+Pn+6Wx7wMyTC3+v1fzuSR5W4bvxB+Mt9r4WIbg+OAM9yRcbcgFYAECIQBz/WmG1UN/\nv6pe0t2LLSqyWu9J8utJfjHDPQy3ZrjW7bIMofL/TXLCEouhLHW92Las4Ebr3f3UqvpYhuvsHpUh\nPP1nhvvZvWgNV+hcyKsz3NPwERlC6d4ZVvB83VjbuVX1Mxmuw3twhmB1XYYQ9rEM7/9r47HOSvL8\nDNMmH5BhZPDiDDejf2l3v33euR+Z4TYND0hyVIZpuRdk8ZvLZ6zpH6vqAeO5H55h9PiMDIsQHZd5\ngXB8D/fJMNL8oPE9fiLJr2RYnGehQLjo59LdV46L5zw/wyjhvZJ8Psmzk7x4keMBsEpuTA8AADBR\nriEEAACYKIEQAABgogRCAACAiRIIAQAAJkogBAAAmCiBEAAAYKIEQgAAgIkSCAEAACZKIAQAAJgo\ngRAAAGCi/n+8mxEc/vvfsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116126160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.title(\"RMSE from RNN model\")\n",
    "plt.xlabel(\"RMSE on test data\",size=20)\n",
    "plt.ylabel(\"Block Count\",size=20)\n",
    "plt.hist(sorted(r))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.990110813153656"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sorted(r)[10:22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.02168966635621,\n",
       " 4.897650898309291,\n",
       " 9.56747554287036,\n",
       " 10.378926388773236,\n",
       " 11.371406257324608,\n",
       " 11.921874592652117,\n",
       " 15.512145939797165,\n",
       " 18.878151222321453,\n",
       " 21.82828338773885,\n",
       " 22.85023979200875,\n",
       " 23.06675066026979,\n",
       " 25.58673540942206]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(r)[10:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
